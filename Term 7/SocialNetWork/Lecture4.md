# **社会与经济网络**
## **第四讲：随机网络形成模型**
**邢亦青**
**xingyq@nsd.pku.edu.cn**

---

# **纲要**

-   **第一部分：背景与基础**
    -   网络的定义与特征 (1,2)
    -   经验背景 (3)
-   **第二部分：网络形成**
    -   随机网络模型 (4,5)
    -   策略网络模型 (6, 11)
-   **第三部分：网络与行为**
    -   扩散与学习 (7,8)
    -   网络博弈 (9)

---

## **4.1 Erdos-Renyi (1959,1960) 随机图**

-   **设定**:
    -   $n$ 个节点
    -   每条边都以某个概率 $p$ 独立形成
-   **作为基准模型**: $G(n, p)$

### **随机网络示例：50个节点**

#### **p = 0.01**
许多孤立节点
![](https://storage.simpletex.cn/view/fThuwunBoYhaUh6cs21C0GhPLbLSr2LFE)

---

#### **p = 0.02**
许多孤立节点，同时出现几个组成部分。
![](https://storage.simpletex.cn/view/fGxKn3D4AWAH7KVtLAqNL26qtnCiLRBfi)

---

#### **p = 0.03**
![](https://storage.simpletex.cn/view/f87gdgpE7raB5vrdQzDc3LsTNzZ9haoKY)

---

#### **p = 0.05**
![](https://storage.simpletex.cn/view/fwXlkaA6sDs5KD5rSe8wGRXuKmBfQMMEE)

---

#### **p = 0.08**
连接更紧密，边数量更多。
![](https://storage.simpletex.cn/view/fuhhn6YZiKCNp9UHXgoz8yLpXKqCk9Nle)

---

## **4.2 聚类系数 (Clustering Coefficient)**

**问题**：节点 $i$ 的朋友之间互为朋友的比例是多少？

**定义**：
$$
Cl_i(g) := \frac{|\{kj \in g \mid k,j \in N_i(g)\}|}{\binom{|N_i(g)|}{2}} = \frac{\#\{kj \in g \mid k,j \in N_i(g)\}}{\#\{kj \mid k,j \in N_i(g)\}}
$$

其中：
-   $N_i(g)$ 代表节点 $i$ 的邻居集合。
-   **分子**：节点 $i$ 的邻居 $k$ 和 $j$ 之间存在的连接数。
-   **分母**：节点 $i$ 的邻居 $k$ 和 $j$ 之间可能存在的连接总数。

![](https://storage.simpletex.cn/view/f1B5zkRKvMwgLyoRmuHrwdHB7woY6CyLt)

---

### **网络的聚类度量**

对于整个网络而言，有两种常用的计算方法：

1.  **平均聚类系数 (Average Clustering Coefficient)**
    -   每个节点权重相等。
    $$
    Cl^{avg}(g) = \frac{1}{n} \sum_i Cl_i(g)
    $$

2.  **总体聚类系数 (Global Clustering Coefficient)**
    -   每对朋友的权重相等；度数高的节点获得更多权重。
    $$
    Cl(g) := \frac{\sum_i \#\{kj \in g \mid k,j \in N_i(g)\}}{\sum_i \#\{kj \mid k,j \in N_i(g)\}} = \frac{3 \times \text{网络中的三角形数量}}{\text{网络中所有节点的连接三元组数量}}
    $$

> [!How to understand the calculation?]
> 这是一个非常好的问题。这个公式乍看之下有点复杂，但如果把它拆解成几何概念（三角形和三元组），就会变得非常直观。
> 
> 总体聚类系数（Global Clustering Coefficient），也称为传递性（Transitivity），衡量的是整个网络中“**朋友的朋友也是朋友**”这一现象的普遍程度。
> 
> 我们分三步来理解这个等式：
> 
> ### 第一步：直观定义（核心思想）
> 
> 抛开数学符号，这个系数想要回答的问题是：
> 
> 在整个网络中，如果我们随机找到**拥有共同朋友的两个人**（比如 A 和 C 都有朋友 B），那么 **A 和 C 也是朋友**的概率有多大？
> 
> 用几何形状来说：
> - **分母**衡量的是网络中有多少个“潜在的三角形”（也就是“开放的三角形”或 V 型结构）。
> - **分子**衡量的是这些潜在的三角形中，有多少真正“闭合”成了完整的三角形。
> 
> ---
> 
> ### 第二步：理解几何概念（三元组与三角形）
> 
> 为了解释公式右侧的文字描述，我们需要定义两个概念：
> 
> **1. 连接三元组 (Connected Triple)**
> 这是一个由三个节点和两条边组成的结构，看起来像一个“V”或者一个张开角的铰链。
> 例如：$k - i - j$。
> 这里，$i$ 是**中心节点**，$k$ 和 $j$ 是 $i$ 的邻居。这代表 $k$ 和 $j$ 有一个共同朋友 $i$。这就是一个“潜在的三角形”。
> 
> **2. 三角形 (Triangle)**
> 这是一个由三个节点和三条边组成的闭合结构。
> 例如：$i, j, k$ 三个点两两相连。
> 这意味着 $k$ 和 $j$ 不仅有共同朋友 $i$，他们自己也是朋友。三角形代表了“实现了的聚类”。
> 
> ---
> 
> ### 第三步：破解公式的等价性
> 
> 现在我们来看看为什么求和公式等于几何公式。
> 
> #### 1. 分析分母 (Denominator)
> 
> $$ \sum_i \#\{kj \mid k,j \in N_i(g)\} $$
> 
> *   **含义**：我们遍历网络中的每一个节点 $i$，把它当作“中心节点”。然后数出 $i$ 有多少对邻居 $(k, j)$。
> *   **几何对应**：每一对 $i$ 的邻居 $(k, j)$，实际上就构成了一个以 $i$ 为中心的 **连接三元组** ($k-i-j$)。
> *   **总和**：当我们把所有节点 $i$ 作为中心节点的情况都加起来时，我们实际上数完了网络中**所有可能的连接三元组**。
> 
> **结论：** 分母 = **网络中所有节点的连接三元组数量**
> 
> #### 2. 分析分子 (Numerator) 和那个 "3"
> 
> $$ \sum_i \#\{kj \in g \mid k,j \in N_i(g)\} $$
> 
> *   **含义**：我们再次遍历每一个节点 $i$（作为中心）。查看它的每一对邻居 $(k, j)$，如果 $k$ 和 $j$ 之间**真的有边连接** ($kj \in g$)，我们就计数。
> *   **几何对应**：如果 $k-i-j$ 是连通的，并且 $k-j$ 也是连通的，那么 $i, j, k$ 就形成了一个完整的**三角形**。
> *   **为什么是 3 倍？（关键点）**：
>     这个求和公式会**重复计数**同一个三角形。
>     想象一个三角形，由节点 A, B, C 组成。
>     1.  当求和进行到 $i = A$ 时，我们发现邻居 B 和 C 相连。计数 +1。
>     2.  当求和进行到 $i = B$ 时，我们发现邻居 A 和 C 相连。计数 +1。
>     3.  当求和进行到 $i = C$ 时，我们发现邻居 A 和 B 相连。计数 +1。
> 
>     同一个三角形 A-B-C，在这个求和过程中被它的三个顶点分别作为中心节点时，一共被数了 **3次**。
> 
> **结论：** 分子 = 该求和结果 = **$3 \times$ 网络中的三角形数量**
> 
> ---
> 
> ### 总结
> 
> $$
> Cl(g) = \frac{\text{实际上存在的“朋友的朋友也是朋友”的情况（闭合三角形）}}{\text{所有“朋友的朋友”的情况（连接三元组）}}
> $$
> 
> 之所以公式里有 $3 \times$ 和求和符号，是因为：
> 
> 1.  **分母的求和**通过遍历所有中心点，数出了所有的“连接三元组”（潜在三角形）。
> 2.  **分子的求和**通过遍历所有中心点，数出了所有闭合的情况。因为一个三角形有三个顶点，每个顶点都能当一次“中心”，所以每个三角形被数了 3 次。
> 
> 为了得到正确的比例，我们要么在分子用“3 $\times$ 三角形数”除以“三元组数”（如您的公式所示），要么用“三角形数”除以“三元组数 / 3”。它们表达的是同一个意思。
> 
> **一句话理解**：这个公式衡量了网络中所有的“V”型结构，最终闭合成“△”型结构的比例。

#### **聚类系数的差异图示**
![](https://storage.simpletex.cn/view/fkyi8Ck9Lg9NM2D0KYd6k1afIrZGqUszD)

Let's now turn to the $n$ case:
- for the nodes in the cliques, we have $Cl_{i}(g)=1$
- for the central node, we have its # of neighbor is $3n$ so the cluster number is $$
\frac{3n}{C_{3n}^2}=\frac{3n}{3n(3n-1)}\times 2=\frac{2}{3n-1}
$$
so we have the $$
Cl^{avg}=\frac{1}{3n+1}\left( 3n+\frac{2}{3n-1} \right)
$$
and it's easy to show that $$
\lim_{ n \to \infty } Cl^{avg}=1
$$

---

## **4.3 E-R 随机网络中的聚类**

回顾节点 $i$ 的聚类系数定义：
$$
Cl_i(g) = \frac{\#\{kj \in g \mid k,j \in N_i(g)\}}{\#\{kj \mid k,j \in N_i(g)\}}
$$

**问题**：在 Erdos-Renyi 随机网络中，$Cl_i(g)$ 等于多少？

**回答**：它的期望值就是 $p$。

-   **直观理解**：在 $G(n,p)$ 模型中，所有的边都是独立同分布的。节点 $i$ 的任意两个邻居之间的连接概率就是 $p$，这与其他任何边的存在与否都无关。
-   **推论**：如果节点的平均度 $d$ 有界且 $n$ 很大，那么 $p = d/(n-1)$ 会随着 $n$ 的增长趋近于 0，这意味着聚类系数也会趋近于 0。

### **真实世界中的聚类**

真实网络的聚类系数远高于 E-R 随机网络的预测值！

-   **监狱中的友谊关系**：0.31 (MacRae 60) vs. E-R 预测值 0.0134
-   **论文合著关系**:
    -   数学领域: 0.15 (Grossman 02) vs. E-R 预测值 0.00002
    -   生物学领域: 0.09 (Newman 01) vs. E-R 预测值 0.00001
    -   经济学领域: 0.19 (Goyal et al 06) vs. E-R 预测值 0.00002
-   **万维网 (WWW)**：
    -   网页链接: 0.11 (Adamic 99) vs. E-R 预测值 0.0002

---

## **4.4 "小世界"模型 (Watts and Strogatz 98, Nature)**

**动机**：Erdos-Renyi 模型缺失了什么？
-   **聚类**：E-R 模型预测的聚类系数接近 0，这与现实世界严重不符。

| 规则网络 (Regular) | 随机网络 (Random) |
| :--- | :--- |
| ![](https://storage.simpletex.cn/view/fMeDDYC6GVZHtIlzuIfY07VZdcSkIwU2K) | ![](https://storage.simpletex.cn/view/fYgEkgGKHIcEG0xuhN1VGBXkB1GFfVkxA) |
| **高聚类** | **低聚类** |
| **大直径** | **小直径** |

**"小世界"模型的思想**：通过"重连"一些边，在保持高聚类系数的同时，显著降低网络的直径。

![](https://storage.simpletex.cn/view/fQDecVNuSOLBqw2cLbtdaWkG1mhwtlA1d)
<center>p=0 (规则)   (随机性增加) p=1 (随机)</center>

**模型构建过程**：
1.  从一个环状格网络开始（具有高聚类和高直径）。
2.  以概率 $p$ 随机地重连网络中的每一条边。
    -   当 $p$ 较小时，少数重连的“捷径”可以大大降低网络直径。
    -   同时，由于大部分局部结构得以保留，网络仍然维持较高的聚类系数。

---

### **思考：为什么需要网络形成模型？**

> “一个科学理论的强度与它能解释的现象的多样性及其简单性有关。随着更多科学证据的收集，一个科学理论可能会被修改，如果它不能适应新的发现，最终会被摒弃；在这种情况下，就需要一个更准确的理论。”
> -- 维基百科关于“科学理论”的词条

---

## **4.5 E-R 随机网络 $G(n,p)$ 中的度分布**

-   **回顾 $G(n, p)$**:
    -   $n$ 个节点，每条边以概率 $p > 0$ 独立同分布地形成。
-   **问题**：一个节点拥有 $d$ 条边的概率是多少？

### **泊松随机网络的度分布**

一个节点拥有 $d$ 条边的概率服从**二项分布**：
$$
P(d) = \binom{n-1}{d} p^d (1-p)^{n-1-d}
$$

当 $n$ 很大，$p$ 很小时，这可以近似为一个**泊松分布**：
$$
P(d) \approx \frac{\lambda^d e^{-\lambda}}{d!}
$$
其中，$\lambda = (n-1)p$ 是期望度数。

---

### **背景：用泊松分布近似二项分布**

**示例**: 设 $n-1 = 200$, $p = 0.05$ → 期望度数 $\lambda = (n-1)p = 10$

| d (连接数) | 二项分布概率 | 泊松分布概率 |
| :--- | :--- | :--- |
| **6** | 0.061 | 0.063 |
| **7** | 0.090 | 0.090 |
| **8** | 0.114 | 0.113 |
| **9** | 0.128 | 0.125 |
| **10** | 0.128 | 0.125 |
| **11** | 0.117 | 0.114 |
| **12** | 0.097 | 0.095 |

**图示**:
![](https://storage.simpletex.cn/view/fWnhpIhtcd6TGPlZ05PBX91QL5ibC3Rpe)

---

### **真实世界网络的度分布**

#### **万维网 (Albert, Jeong, Barabasi 1999)**
![](https://storage.simpletex.cn/view/fnFpcSohz8ck4ahaIkgPbomIYFw8Zsb3H)

#### **引文网络：肥尾分布 (Price 1965, Science)**

**观察**：
-   高度和低度的节点数量比随机网络（泊松分布）预测的要多得多。
-   与随机网络相比，真实网络的度分布呈现“**肥尾 (Fat Tail)**”特征。
-   这种现象也存在于其他领域，如财富分布、城市规模、词语使用频率等 (Pareto, Yule, Zipf, Simon)。

---

# **增长型随机网络**

-   **动机**：
    -   E-R 随机网络的度分布是泊松分布（瘦尾）。
    -   真实世界网络的度分布是肥尾分布。
-   **目标**：
    -   构建能生成非泊松度分布（特别是肥尾分布）的网络模型，以更好地匹配真实世界。

---

## **4.6 增长模型 I：均匀随机 (Uniform Random Attachment)**

这是一个简单的基准增长模型。

-   **模型规则**：
    1.  从 $m$ 个完全连接的节点开始。
    2.  每个时期都有一个新节点诞生。
    3.  新节点与 $m$ 个已存在的节点形成连接。
    4.  这 $m$ 个已存在的节点是**等概率地**从所有现有节点中选出的。

### **期望度数的分布**

-   在时刻 $t$，一个在时刻 $i$ ($m < i < t$) 诞生的节点，其期望度数为：
    $$
    E[d_i(t)] = m + \sum_{k=i+1}^{t} \frac{m}{k}
    $$
    其中，$m$ 是它诞生时形成的边，$\sum \frac{m}{k}$ 是后续新节点连接到它的期望边数。

### **连续时间近似**

当 $t$ 很大时，我们可以用积分来近似求和，得到度数随时间变化的微分方程：
$$
\frac{d}{dt} d_i(t) = \frac{m}{t}
$$
结合初始条件 $d_i(i) = m$，求解可得：
$$
d_i(t) = m + m \ln\left(\frac{t}{i}\right)
$$

### **累积度分布函数 (CDF)**

在某个时刻 $t$，期望度数小于 $d$ 的节点 $i$ 满足：
$$
m \left(1 + \ln\left(\frac{t}{i}\right)\right) < d
$$
解得这些节点的诞生时刻 $i$ 满足：
$$
i > t \cdot e^{-\frac{d-m}{m}}
$$
令 $i^* = t \cdot e^{-\frac{d-m}{m}}$。因此，度数小于 $d$ 的节点比例（CDF）为：
$$
F_t(d) = P(D < d) = \frac{t - i^*}{t} = 1 - e^{-\frac{d-m}{m}}
$$

这个结果表明，期望度数 $d-m$ 服从均值为 $m$ 的**指数分布**。



### **我们达到目标了吗？**

-   **回顾目标**：生成一个能更好匹配真实世界“肥尾”度分布的模型。
-   **结果**：我们得到了一个指数分布。
-   **结论**：这不是泊松分布，但指数分布通常被认为是瘦尾和肥尾分布的临界点。我们还没有完全实现“肥尾”特性。

**思考**：如何获得更肥的尾部？
-   均匀随机连接的度增长率为：$\frac{d}{dt} d_i(t) = \frac{m}{t}$
-   为了体现“富者愈富”（拥有更多朋友会带来更多新朋友），我们可能需要一个与节点当前度数相关的增长率，例如：
    $$
    \frac{d}{dt} d_i(t) \propto d_i(t)
    $$
这引出了**优先连接 (Preferential Attachment)**模型。

---
# **备用内容：随机网络的极限性质**

-   **研究方法**：为了推断随机网络的性质，我们通常通过研究当节点数 $n \to \infty$ 时网络的极限行为。
-   **关键思想**：考察一系列连接概率为 $p(n)$ 的 Erdos-Renyi 随机网络，并推断其性质。

### **阈值函数 (Threshold Function) 与相变 (Phase Transition)**

对于一个网络性质 $A(n)$，如果存在一个函数 $t(n)$ 满足：
-   当 $p(n)/t(n) \to \infty$ 时（更稠密的网络），$Pr[A(n) \text{ 成立}] \to 1$。
-   当 $p(n)/t(n) \to 0$ 时（更稀疏的网络），$Pr[A(n) \text{ 成立}] \to 0$。

那么，$t(n)$ 就是性质 $A$ 的**阈值函数**，在 $p(n)$ 跨越这个阈值时，网络会发生**相变**。

---

### **E-R 随机网络的阈值示例**

对于一个有 $n=50$ 个节点的网络，不同性质出现的概率阈值 $p$ 大致如下：
-   $p \approx 1/n^2 = 0.0004$
    -   (平均度 = $1/n$)
    -   网络中**出现第一条边**。
-   $p \approx 1/n^{1.5} \approx 0.0028$
    -   (平均度 = $1/\sqrt{n}$)
    -   网络中出现**至少有三条边的组分**。
-   $p \approx 1/n = 0.02$
    -   (平均度 = 1)
    -   网络中**出现环**。
    -   网络中出现唯一的**巨组分**（一个大小与 $n$ 相当的组分）。
-   $p \approx \ln(n)/n \approx 0.078$
    -   (平均度 = $\ln(n)$)
    -   整个网络变为**连通**的。

# 阈值函数与相变：在 $G(n,p)$ 中的严谨推导

本文在 Erdős–Rényi 随机图 $G(n,p)$ 框架下，给出若干典型性质的**阈值函数**推导。我们使用标准工具：第一/二矩法（first/second moment method）、小子图计数（small subgraph counts）、以及在稀疏区间 $p=\Theta(1/n)$ 的分枝过程近似（Galton–Watson）。

---

## 0. 预备：阈值函数（coarse threshold）的定义

对性质 $A=A(n)$，若存在函数 $t(n)$ 使得
- 当 $p(n)/t(n)\to\infty$ 时，$\Pr[A(n)\ \text{成立}]\to 1$；
- 当 $p(n)/t(n)\to 0$ 时，$\Pr[A(n)\ \text{成立}]\to 0$，

则称 $t(n)$ 为性质 $A$ 的（粗）**阈值函数**，并说 $p$ 跨越 $t(n)$ 时发生**相变**。本文讨论的阈值均为此意义下的“粗阈值”（忽略常数因子，关注主项指数）。

---

## 1. $G(n,p)$ 的基本计数与工具

- 总边数：$N=\binom{n}{2}\sim \frac{n^2}{2}$，边指示独立，$\#\text{edges}\sim \mathrm{Bin}(N,p)$，$\mathbb{E}[\#\text{edges}]=Np$。
- 小子图 $H$（有 $v(H)$ 个顶点、$e(H)$ 条边）的出现计数期望
  $$
  \mathbb{E}[X_H]\asymp n^{v(H)}p^{e(H)}.
  $$
  当 $\mathbb{E}[X_H]\to 0$ 时通常 $X_H=0$ 以高概率；当 $\mathbb{E}[X_H]\to\infty$ 且相依性可控时，$X_H>0$ 以高概率。
- 长度为 $\ell$ 的简单环（cycle）数的期望：$\mathbb{E}[C_\ell]\sim \frac{n^\ell}{2\ell}p^\ell$。
- 在 $p=\frac{c}{n}$ 区间，BFS 层数分布可由泊松均值为 $c$ 的 Galton–Watson 过程近似。

---

## 2. 阈值一：**出现第一条边**（“图非空”）

性质：$A_1=\{\text{存在至少一条边}\}$。

- “无边”概率：$\Pr[\text{no edge}]=(1-p)^N\approx \exp(-pN)$。
- 若 $pN\to 0$，则 $\Pr[\text{no edge}]\to 1$，即 $A_1$ 失败；
- 若 $pN\to \infty$，则 $\Pr[\text{no edge}]\to 0$，即 $A_1$ 成立。
- 因此阈值满足 $pN\asymp 1$，即
  $$
  t_1(n)\asymp \frac{1}{\binom{n}{2}}\sim \frac{2}{n^2}.
  $$
> 备注：常以“$1/n^2$ 量级”描述，常数因子不影响阈值指数。

---

## 3. 阈值二：**出现“至少有 3 条边”的组分**

这一性质最早出现的“最省边”候选是**大小为 4 的树成分**（3 条边）：即 $K_{1,3}$（星）或 $P_4$（4 点路径），均是 4 点 3 边且无环。我们计算“**作为一个成分**出现”的期望数，并据此得到阈值。

记 $X$ 为“4 点树成分”的个数（把每个 4 顶点子集诱导的图恰为一棵树，且对外无边视为一个成分）。则
$$
\mathbb{E}[X]
=\binom{n}{4}\cdot T_4\cdot p^3(1-p)^{3}\cdot (1-p)^{4(n-4)},
$$
其中 $T_4$ 为 4 个带标号顶点的生成树数量（Cayley 定理：$T_4=4^{4-2}=16$），$(1-p)^3$ 是这 4 点内部“非边”的概率，$(1-p)^{4(n-4)}$ 确保这 4 点对外无边（从这 4 点向外的潜在边数为 $4(n-4)$）。

当 $p\to 0$ 时，$(1-p)^3\to 1$，且
$$
(1-p)^{4(n-4)}\approx \exp(-4np)\quad (\text{忽略低阶}).
$$
于是
$$
\mathbb{E}[X]\asymp \frac{n^4}{24}\cdot 16\cdot p^3\cdot e^{-4np}
\asymp n^4 p^3 e^{-4np}.
$$
考察尺度 $p=n^{-\alpha}$：
- 若 $\alpha>1$，则 $e^{-4np}=e^{-4n^{1-\alpha}}\to 1$，故 $\mathbb{E}[X]\asymp n^{4-3\alpha}$。
  - 当 $4-3\alpha>0$（即 $\alpha<\tfrac{4}{3}$）时，$\mathbb{E}[X]\to\infty$；
  - 当 $4-3\alpha<0$（即 $\alpha>\tfrac{4}{3}$）时，$\mathbb{E}[X]\to 0$。
- 若 $\alpha=1$，则 $e^{-4np}=e^{-4}$ 是常数，$\mathbb{E}[X]\asymp n\to\infty$。
- 若 $\alpha<1$，指数因子使 $\mathbb{E}[X]\to 0$（但该区间已远大于我们感兴趣的稀疏规模）。

因此 **临界指数为 $\alpha=\tfrac{4}{3}$**，即
$$
t_2(n)\asymp n^{-\frac{4}{3}}.
$$
更严格地，可用二矩法控制方差，得到：当 $p\ll n^{-4/3}$ 时，$X=0$ 以高概率；当 $p\gg n^{-4/3}$ 时，$X>0$ 以高概率，从而给出阈值（忽略常数因子）$n^{-4/3}$。

> **重要更正**：有时会看到 $n^{-3/2}$ 的说法，但对“**出现一个至少 3 边的成分**”而言，最早触发的确是“4 点树成分”，其阈值为 $n^{-4/3}$，而非 $n^{-3/2}$。三角形（3 点 3 边）作为成分的阈值是 $n^{-1}$（见 §4），反而更“晚”。

---

## 4. 阈值三：**出现环（存在某个长度 $\ell\ge 3$ 的简单环）**

对固定长度 $\ell$，环的期望数
$$
\mathbb{E}[C_\ell]\sim \frac{n^\ell}{2\ell}p^\ell.
$$
- 若 $p\ll \frac{1}{n}$，则对每个固定 $\ell$，$\mathbb{E}[C_\ell]\to 0$；联合界（或更细致的 Poisson 逼近）给出“无环”以高概率。
- 若 $p\gg \frac{1}{n}$，则对某些 $\ell$，$\mathbb{E}[C_\ell]\to\infty$，以高概率存在环。

因此
$$
t_{\mathrm{cycle}}(n)\asymp \frac{1}{n}.
$$
这与经典“**临界窗口**”一致：$p=\frac{c}{n}$ 时图处于稀疏临界区域，出现有限多（期望常数级）的短环与**至多一个**“单环组分”（unicyclic component）是典型形态。

---

## 5. 阈值四：**巨组分（giant component）的出现与唯一性**

设 $p=\frac{c}{n}$。用均值为 $c$ 的泊松分枝过程近似 BFS：

- 若 $c<1$（**亚临界**），分枝过程灭绝概率为 1，最大组分规模为 $O(\log n)$，图主要由小树和少量单环组分构成。
- 若 $c>1$（**超临界**），分枝过程以正概率不灭绝。令 $\rho(c)$ 为不灭绝概率，则图中以高概率出现一个**唯一的巨组分**，其顶点比例 $\theta(c)$ 为分枝过程的存活概率（满足 $\theta=1-\exp(-c\theta)$），其余组分规模为 $O(\log n)$。

故
$$
t_{\mathrm{giant}}(n)\asymp \frac{1}{n}.
$$
> 与“出现环”的阈值同阶，这是 $G(n,p)$ 的核心现象之一：在 $p\approx 1/n$ 的临界附近，图从“全是小树/少量单环”的相，跃迁到“存在线性规模的唯一巨组分”的相。

---

## 6. 阈值五：**连通性（图整体连通）**

连通性的主要障碍是**孤立点**。令 $I$ 为孤立点个数。则
$$
\mathbb{E}[I]=n(1-p)^{n-1}\approx n e^{-pn}.
$$
取
$$
p=\frac{\ln n + c}{n},
$$
则
$$
\mathbb{E}[I]\to e^{-c}.
$$
经典结果表明，在该尺度下 $I$ 服从近似 Poisson$(e^{-c})$，且除孤立点外的其他不连通障碍在该量级可忽略。于是
$$
\Pr[\text{连通}]\to \Pr[I=0]=e^{-e^{-c}}.
$$
因此连通性的阈值为
$$
t_{\mathrm{conn}}(n)\asymp \frac{\ln n}{n}.
$$

---


#### **图示 ($n=50$)**

-   **p = 0.01** (低于巨组分阈值)
![](https://storage.simpletex.cn/view/fbZOXVeI4T4XGlSIlfeXYQ3VHDmQKGg6I)

-   **p = 0.03** (高于巨组分阈值)
![](https://storage.simpletex.cn/view/f4VeKfgUMsHYXC7MRXNcDaDYlSLMTtL8Y)

-   **p = 0.10** (高于连通性阈值)
![](https://storage.simpletex.cn/view/ft2wnGuvAzxvAGywGF9tgd6rRXnn4GGLM)